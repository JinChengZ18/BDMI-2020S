# 39-Day7



## numpy

### bacics

n维数组对象

numpy.empty

numpy,zero

广播操作 Bradcast

###### 相乘

​	形状相同，对位相乘

形状变换

​	numpy.reshape(arr,newshape,order='c')

arr	要改变的数组

newshape 新形状，应该兼容原有形状

order  ‘C“按行，F列,A原顺序，K内存顺序等



numpy.squeeze（arr,axis) 删除某一维度

numpy.concatenate(a1,a2,....axis)  连接形状相同的多个数组

numpy.stack(arrays.axis)  按照指定的轴堆叠数组

​	.hstack	水平堆叠

shape A:(6,)



##### 函数操作

sin.cos

add,subtract,multiply,divide  必须符合形状关系

统计函数，找最大最小值

numpy排序、条件筛选  numpy,sort

线性代数库

numpy载入与保存

load save



## 深度学习

人工神经元抽象成函数

人工神经元模拟布尔电路

人工神经网络机构

人工神经元网络的negligible



##### 人工神经元

单个人工神经元

​	一组输入的线性加权

​	经过一个非线性变换进行输出

sigmod  逻辑提斯函数 取 0,1

relu  整流线性单元  max(0,x)

##### 激活函数

非线性函数

![image-20200401135939518](C:\Users\huawei\AppData\Roaming\Typora\typora-user-images\image-20200401135939518.png)



神经元1  relu整流线性单元

F(w,x)经过调节权重w，改变输出结果

​	书友输入：加权叠加

​	激活函数numpy表示

人工神经元模拟和布尔电路

​	AND运算  OR运算  利用sigmod函数实现

​	在该返回0的时候线性加权得到负数

​	该返回1的时候线性加权得到一个不是太小的整数

​	

XOR运算

​	x1 xor x2   

​	= or

用与非门可以实现一个复杂的布尔电路

##### 例 性别判断神经元

###### 分类问题

输入特征 头发长度，身高体重等

各种特征的权重



### 人工神经网络

按照拓扑连接结构，将大量的神经元之间连接以来，构成人工神经元的网络结构

拓扑结构：不同神经元之间的连接关系

前馈网络、反馈网络、记忆网络

##### 多层前馈网络

FNN  多层全连接网络，多层感知机，密集网络

输入层，隐藏层，输出层

前馈网络  计算快，可并行化

##### softmax处理

在输出层计算一个概率分布向量，使得最大值变得更为突出

![image-20200408131049798](C:\Users\huawei\AppData\Roaming\Typora\typora-user-images\image-20200408131049798.png)

##### logit

吧（0,1）的数变换到负无穷到正无穷

![image-20200408131147036](C:\Users\huawei\AppData\Roaming\Typora\typora-user-images\image-20200408131147036.png)

##### 图像识别

先特征提取

然后分类



### 数学基础

##### 典型网络

确定权重参数

进行输出

计算差异

使得差异最小化

##### 交叉熵

分类问题的损失函数

![image-20200408133031005](C:\Users\huawei\AppData\Roaming\Typora\typora-user-images\image-20200408133031005.png)



卷及运算

​	一种张良运算

​	输入多维数组，卷积核kernel也是多维数组

​	卷积核的参数由学习得到

#### 卷机网络CNN

每一个卷积层后通常紧跟着一个下采样层，如最大最大池化

权重共享   局部区域的权重共享



#### 循环网络结构RNN

目标，损失函数，网络输出，激活函数，输入



#### 人工神经网络的能力

图像分类	

手写数组，MINIST数据集

​	灰度图像，0.255

​	二值图像		

时尚MNIST数据集

​	彩色图像，RGB



#### 深度学习相关的数学原理

##### 基本数学概念

映射，函数，函数逼近问题，泛函分析

##### 前馈网络万能近似器

多层前馈网络提供了一种万能近似框架

万能近似定理

##### 循环网络的近似能力

用sgmoid激活函数的RNN是图灵完备的：

​	任意一个能用图灵计算出的函数，都可以用RNN计算

##### 实际中存在的问题

万能近似定理

理论上：存在一个足够大的网络能达到我们希望的任意精度

但实际上，不一定能学到





### 深度神经网络进阶

#### 交叉熵

分类问题的损失度量函数

对于回归任务：通过均方误差的公式来计算损失

对于分类任务，通过交叉熵的公式来计算损失

##### 梯度下降法

对于可微分的下凸函数，

如果F(X)在某点有定义，那么F(X)在该点沿着梯度相反的方向下降最快

##### 损失函数对梯度的权重计算，反向传播

$$

$$



梯度算子，更新全中数值

Loss=J(θ)，是权重根数值的函数

##### 随即梯度下降法

先随机初始化权重和偏差

在随机取一个样本，计算偏差

根据网络的结果，从最后一层开始，逐层计算每层权重的偏导数

逐层调整每层的权重，产生新的权重值

随机选取下一个样本



##### 深度网络实际训练过程

分批训练  batch

整个数据集称为一个batch



##### 小批量训练

分为多个子集，每个子集成为一个迷你批次

每个迷你批次一次送入训练，每训练完一个成为一次迭代  iteration

一次时代epoch 指的是训练集所用训练用本都被送入网络完成一次训练



#### 深度神经网络实现

##### 数值计算-数值量化

数值分析  求解各类数学问题的数值计算方法

计算机进行数值计算的基本功于

WORD固定，需要对数值进行量化  single,double float

##### 数值计算-误差来源

模型误差

观察误差

方法误差、截断误差

舍入误差

##### 数值计算的基本原则

数值稳定  计算过程中摄入误差不增长

大量级的数被近似为无穷大的时候发生上溢

##### 求导运算

数值微分  根据导数的定义，差分，有误差

符号微分	精确的公式

自动微分	直接返回导函数，不对运算进行符号化

##### 符号微分原理

将表达式本身看作符号的运算，直接得到求导结果

按照定义基本运算Op

定义初等函数的导数运算

预定义四则函数的运算求导

定义链式求导法则

张量

##### 数据Tensor表示

Tensor ndarray

计算机处理离散数值的组织方式

Tensor的属性

rank	维数

length  

shape

volume  元素个素

##### 多层前馈网络的张量表示

前馈网络结构

### tensorflow2

常量，variable可变量，placehold  可以往里面填一个值

##### Tensor

人工神经元

