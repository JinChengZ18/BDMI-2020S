# 61-Day8

## 1 自动微分(Automatic Differentiation)
- 求函数微分的解析式（手动）$\rightarrow$ 数值微分（不准确） $\rightarrow$ 符号微分（表达式爆炸）
- 自动微分：基于链式法则，把表达式写成图的形式，对图中的每个环节分别求导（基于链式法则），最后再组合起来。
- 前向传播算的是每个节点$\frac{\partial v_i}{\partial x}$，其中$v_i$是节点，$x$是输入，能得到每个输出对某一输入的偏导；反向传播算的是每个节点$\frac{\partial y}{\partial v_i}$，其中$y$是输出，最后能得到某一输出对每个输入的偏导。神经网络对某一输出对每个输入的偏导更感兴趣，因此更经常采用反向传播算法。

## 2 Tensorflow介绍
- Google Deep Learning Library, Python on top of C++
- tf1.0 $ \rightarrow$ tf2.0 不再需要tf.session()延迟进行运算
- 底层：Eigen:线性代数C++模板库

## 3 CNN & RNN
- CNN: 自动驾驶、人脸识别；通过2D, 3D卷积核提取特征；LeNet，ResNet，VGG
- RNN: 时间序列数据处理：手写识别、语音识别、诗歌填词、代码生成、股价预测、天气预测、机器翻译、图片注释、对联撰写
- 训练循环网络时，常常需要进行梯度截断以避免梯度爆炸的问题
- 综合运用：图片注解
- 单个人工神经元：输入是1d，参数是1d，输出是标量（0d）
- Dense：全连接层 （超参数：层数）：input: L , weight: L*U, output: U
- MLP: 多层感知机（多个全连接层）：用于解决分类问题。最后输出概率向量需要通过Softmax层
- CNN卷积的另一种理解：局部区域的权重W共用，每个卷积层后通常紧跟着下采样层。
- Conv2D：二维卷积，超参数（卷积核个数，核大小，padding,  strides）
- Pooling2D：（pooling_type, window_shape, padding, strides）不改变tensor的深度，只改变大小
- Dropout：解决过拟合
- RNN：keras.layers.RNN
- LSTM：增加了记忆单元  keras.layer.LSTM