# 第七次课堂小结

## numpy

数组运算

·建立数组 np.array（）

·numpy广播

·numpy.transpose(aarr,axes)

·numpy.squeeze

·numpy.reshape

## 人工神经元

### 介绍

激活函数

调节权重

### 模拟布尔电路

sigmoid函数

### 运算

权重、偏置量是可调的

二进制

**relu解决异或门**

## 结构

二元分类，判断性别

前馈、反馈、记忆网络

### 典型网络结构

卷积网络CNN：前馈网络

循环网络RNN：反馈网络

#### 卷积网络

卷积运算

权重共享

## 人工神经网络能力

### 图像分类

图像表示——每个像素是数字

·手写数字MNIST：

灰度图像（8位2进制），二值图像

·时尚MNIST

24位2进制，RGB

示例：softmax

### 数学原理

映射、函数、函数逼近、泛函分析

前馈网络万能近似器

循环网络近似能力：图灵完全等价

## 激活函数示例

1. ReLU(x) = max(0,x)
   可用于整流
2. PReLU（x）
3. sigmoid函数 $sigmoid(x) = 1/1+e^{-x}$
4. 饱和型S函数
5. logit函数 log(x/(1-x))
6. softmax 总和为1，可以看成概率 

## 深度学习

### 网络训练

1. 确定目标函数

2. 可微分网络结构：反向传播 自动微分

3. 修正权重

4. 采用带标签的样本进行学习，确定权重

5. 度量函数D(y, y') ，差异值最小

6. 交叉熵:用于**分类**任务；回归任务：**均方误差**

7. 梯度下降法：找到局部极小值，向当前点对应梯度的反方向迭代搜索

   随机梯度下降法：调整权重最小化损失函数

8. 步长/学习率：一般为0.01，如果太小收敛太慢，如果太大震荡

9. page：固定大小的一些储存单元；file：variable list of page

10. read：disk $\rightarrow$buffer

### tensorflow

- tensor：多维数组
- X H N Y W1 W2都是张量





​    

​    









