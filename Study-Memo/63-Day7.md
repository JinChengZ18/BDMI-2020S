# 课程小结

## Numpy

ndarray：多维数组
广播：将低维数组扩展到与高维数组相同的大小以进行计算
reshape：改变数组形状
concatenate：沿某一维对数组进行拼接

## 神经网络

$$
y=f(\sum_{i=1}^NW_iX_i+b)
$$
激活函数：  
$$
sigmoid(x)=\frac{1}{1+e^{-x}}
$$
$$
tanh(X)=\frac{e^x-e^{-x}}{e^x+e^{-x}}
$$
$$
ReLU(x)=\max(x,0)
$$
网络分类：  

* 前馈网络（如CNN）  
* 反馈网络（如RNN）  
* 记忆网络  

Softmax:$g(z_m)=\frac{e^{z_m}}{\sum_ke^{z_k}}$  
有足够多隐藏单元的前馈网络能够以任意精度逼近任何从有限维空间到有限维空间的连续函数  
用Sigmoid的RNN是图灵完备的  
网络训练：
1、确定目标函数
2、可微分网络结构

* 反向传播（BP）
* 自动微分（AD）

3、修正权重
损失函数：

* 平方和
* 均方差
* 交叉熵

交叉熵：
$$
H_{y'}(y)=-\sum_iy_i'log(y_i)
$$
梯度下降法：
$$
\theta=\theta-\eta\cdot\nabla_\theta J(\theta)
$$
随机梯度下降  
小批量随机梯度下降
