# DAY 7

​		今日要点：NUMPY、深度学习、Tensorflow初步

### NUMPY

* NUMPY是用于数组计算的运行速度极快的Python扩展数学程序库。

* N维数组对象ndarray：

  * 一系列同类型数据的集合

  * 包含：指向数据的指针、数据类型(dtype)、数组形状(shape)、跨度元组(stride)

  * 创建：

    ```python
  numpy.array(object, dtype = None, copy = True, order = None, subok = False, ndmin = 0)
    ```

    ###### 参数说明：
  
    | 名称   | 描述                                |
  | ------ | ----------------------------------- |
    | object | 数组或嵌套的数列                    |
  | dtype  | 数组元素的数据类型                  |
    | copy   | 对象是否需要复制                    |
    | order  | 创建数组的样式(C--行/F--列/A--默认) |
    | subok  | 默认返回一个与基类类型一致的数组    |
    | ndmin  | 指定生成数组的最小维度              |
  
  * 其他创建方式：
  
    * numpy.empty(shape, dtype, order)
  * numpy.zeros()：用0填充指定大小的数组
    * numpy.ones()：用1填充指定大小的数组

* 广播(broadcast)：

  * 用于处理不同形状之间数组计算时的机制
  * 让所有参与计算的数组向形状最长的数组看齐，输出数组形状是各个输入数组各维度的最大值

* 数组形状变换：

  * reshape：在不改变数据的条件下改变数组形状

    ```python
    numpy.reshape(arr, newshape, order = 'C')
    ```

  * ravel：在不改变数据的条件下将多维数组展平

    ```python
    numpy.ravel(arr, order = 'C')
    ```

  * transpose：对换数组维度

  * squeeze：从数组中删除单维度条目

* 数组合并：

  * concatenate：沿某轴合并形状相同的两个或多个数组

    ```python
    numpy.concatenate((a1, a2), axis)
    ```

  * stack：沿着新的轴加入一系列数组（hstack/vstack）
  
* 函数操作：

  * 三角函数/算数函数/统计函数/排序/条件筛选/线性代数

* 保存与载入：

  * 以.npy格式文件进行保存与读取

    ```python
    np.save("data.npy",data)
    np.load("data.npy")
    ```



****

### 深度学习

* 人工神经元：基本单位，对于多个输入进行加权线性叠加，再经过非线性激活函数输出。

  * 激活函数：
    * ReLU：整流线性单元：$ReLU(x)=max(x,0)$
    * sigmoid：逻辑斯提函数：$sigmoid(x)=\frac{1}{1+e^{-x}}$
    * ranh：双曲正切函数：$ tanX(x) = \frac{e^x-e^{-x}}{e^x+e^{-x}} $
  * 模拟布尔电路：
    * 通过线性叠加和激活函数可以模拟与门、或门、非门运算。
    * 所有基本逻辑电路均可以通过与非门表示，从而实现复杂的布尔电路
    * 大量人工神经元可以构成人工神经网络

* 人工神经网络：

  * 前馈网络：

    * 分为输入层/隐藏层/输出层

    * 例子：卷积网络(CNN)：分为卷积层/采样层/随机丢弃层，优点：计算快、可并行。

  * 反馈网络：

    * 前一时刻的输出作为下一时刻的输入
    * 例子：循环网络(RNN)

* 深度神经网络训练：

  * 建立网络：
    * 确定目标函数
    * 微分网络结构：反向传播(BP)/自动微分(AD)
    * 调整权重和偏置矩阵

  * 损失函数：
    * 定义损失/成本函数，度量函数$D（y,y')$
    * 回归任务-均方误差/分类任务-交叉熵
  * 优化方法：
    * 梯度下降法
    * 随机梯度下降法
    * 步长/学习率：一般为0.1，过小收敛过慢，过大产生震荡



****

### Tensorflow初步

* tensor：数据的张量表示，相当于多维数组



****

### 总结

​		本节课感觉是承上启下最为关键的一节，做好了笔记一直没有整理，也算是一次复习了，本节学习了深度学习的初步，对两种比较经典的网络结构有了比较直观的认识。不过tensorflow的安装卡了我好久，还好最后处理好了。