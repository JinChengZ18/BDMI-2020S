# BDMI第八次课程小结

 ## 自动微分

### 背景

1. manual differentation(手动微分)：手动算微分
2. numerical differentiation（数值微分）偏导数进行数值近似，简单快速，但不太精确
3. symbolic differentiation（符号微分）通过一些求导法则；可能造成表达爆炸，通用性不够广
4. automatic differentiation（自动微分）

### forward mode

1. 根据graph，对于由$x_1、x_2$求出y，根据链式法则通过中间的$v_1、v_2$等等依次求出偏导，最后得到y对于某一个输入的偏导。
2. 需要对多个输出偏导时，需要进行多次运算
3. **forward mode：dual value**:f(a+bϵ) = f(a)+h'(a)*ϵ

### 反向自动微分

先用forward mode计算图中每个结点的值，再反向计算所有的导数取值

## Tensorflow

### 深度学习框架

- 编程语言（tensorflow会自动微分），解释器（对应计算图），编译器（XLA）

### tensorflow介绍

- 以运算为图的节点，边是张量（传输的多维矩阵）
- keras可以用于快速搭建神经网络
- 求导采用符号微分

## 卷积网络：图像识别等

1. 卷积核是一个多维数组，其中参数由学习算法得到
2. 输出长度计算：

- 输入的长度

- 卷积核大小
and so on

## 循环网络

- 在时间维度上，每一个时间步处理，采用共享的权重
- 适用于时间序列输入，例如对联生成、诗歌、天气预报等等
- 可能有梯度爆炸

### 长短时记忆网络（LSTM）

- 增加了记忆单元、输入们、遗忘门（选择性遗忘记忆单元的内容）、输出门
- 对历史信息进行一次筛选(×) + 输入新信息（+）改进：GRU（门控循环单元）


​	

​	  