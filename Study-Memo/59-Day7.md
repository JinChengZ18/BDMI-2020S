# 课程小结

- Numpy
- 人工神经元和人工神经网络
- 回归与分类

## Numpy

- 用于数组计算的数学库
- 特点：N 维数组对象 ndarray（必须同类型数据）
- 函数
  - 创建
    - numpy.zeros()：依据给定形状和类型返回一个元素全为 0 的数组

      ```python
      numpy.zeros(shape, dtype = float, order = 'C')
      # order: C按行，F按列，A按原顺序，K按内存中的出现顺序
      ```

    - numpy.ones()：依据给定形状和类型返回一个元素全为 1 的数组
    - numpy.empty()：依据给定形状和类型返回一个新的空数组
  - 变形
    - numpy.reshape()：给予数组一个新的形状（维数），而不改变它的数据

      ```python
      numpy.reshape(arr, newshape, order = 'C')
      ```

    - numpy.squeeze()：从数组的形状中删除单维度条目，即去掉 shape 中为 1 的维度

      ```python
      numpy.squeeze(arr, axis = None)
      # axis用于指定需要删除的维度，但必须为单维度
      ```

    - numpy.transpose()：调换数组的行列值的索引值（类似于矩阵转置）
    - 扁平化
      - numpy.ravel()
      - numpy.flatten()
  - 合并
    - numpy.concatenate()：沿指定轴拼接相同形状的多个数组

      ```python
      numpy.concatenate((a1, a2, a3, ...), axis)
      ```

    - numpy.vstack()：垂直合并
    - numpy.hstack()：水平合并
    - numpy.dstack()：deep stack

      ```python
      a = numpy.array([[1, 2],
                       [3, 4]])
      b = numpy.array([[5, 6],
                       [7, 8]])
      c = numpy.dstack([a, b])
      print(c)

      '''
      [[[1 5]
        [2 6]]
       [[3 7]
        [4 8]]]
      '''
      ```

  - numpy.sort()：排序

    ```python
    numpy.sort(arr, axis=-1, kind='quicksort', order=None)
    ```

  - 载入与保存
    - numpy.save()：保存
    - numpy.load()：下载

## DeepLearning

- 人工神经元
  - 即带权重的函数$y=f(\sum_{i=1}^N W_iX_i+b)$，两个重要变量为输入（X）和权重（W）
  - y = f( ∑ <sup>N</sup><sub>i=1</sub> W<sub>i</sub> X<sub>i</sub> + b)
  - 基本模式：多个输入进行加权线性叠加，通过一个非线性激活函数进行输出
  - 激活函数：Sigmoid, softmax, logit, tanh, ReLU

  ```python
  import matplotlib.pyplot as plt
  import numpy as np

  x = np.linspace(-3, 3, 100)

  relu = lambda x: np.maximum(x, 0)
  plt.plot(x, relu(x))

  softplus = lambda x: np.log(1.0 + np.exp(x))
  plt.plot(x, softplus(x))

  sigmoid = lambda x: 1 / (1 + np.exp(-x))
  plt.plot(x, sigmoid(x), color='red', lw=2)

  plt.show()
  ```

  - 人工神经元模拟 bool 电路
    - 利用偏置系数 w<sub>i</sub> 实现
    - 通过线性叠加和激活函数，模拟出与、或、非运算
    - 不能直接模拟出异或运算，需要多个神经元叠加

- 人工神经网络
  - 前馈网络
    - 输出仅传向下一层
    - 理论上前馈网络可以拟合出任何函数，因为有足够多隐藏单元的前馈网络能够以任意精度逼近任何从有限维空间到有限维空间的连续函数
    - 卷积神经网络（CNN）：包括卷积层（卷积核是多维数组，在学习中改变），下采样层（池化层）（最大值或最小值抽样，输入下一层），随机丢弃层（每次学习中随机禁用一些神经元，防过拟合）
  - 反馈网络
    - 当前时间的输出可以作为下一时间的输入
    - 循环神经网络（RNN）：训练完成之前权重矩阵不变；理论上只要给出正确的权重，循环神经网络能完成任何运算；用 Sigmoid 的 RNN 是图灵完备的
  - 记忆网络

- 损失函数
  - 当前输出和预期输出的度量；回归问题采用均方差，分类问题选择交叉熵 H<sub>y'</sub> (y) = - ∑<sub>i</sub> y<sub>i</sub>' log(y<sub>i</sub>)
  - 深度学习，即让网络在不断输出的过程中根据输出和预期的差异调整参数，使得损失函数最小，常用方法是**梯度下降**法
    - θ = θ - η · ∇<sub>θ</sub> J(θ)
    - 找局部极小值，向当前点对应梯度的反方向迭代搜索（用反向链式法则求微分）
    - 下降的速率称为学习率，学习率太大引起震荡，太小则收敛太慢
    - 随机梯度下降算法（SGD）：使用全部数据做一个训练批次。优点是收敛性有保证，缺点是参数更新前需要遍历整个数据集，因此通常设置小批量训练（mini-batch）。

## TensorFlow

- 数据张量表示
  - 张量（Tensor）在形式上与向量（Vector）差别不大，可以表示任意维度的数据
  - 三维：行，列，颜色

- 线性回归

  ```python
  # Optimization process
  def run_optimization():
      # Wrap computation inside a GradientTape for automatic differentiation.
      with tf.GradientTape() as g:
          pred = linear_regression(X)  # 使用当前参数进行预测
          loss = mean_square(pred, Y)  # mean_square 计算当前预测与实际值的差异

      # Compute gradients
      gradients = g.gradient(loss, [W, b])

      # optimizer = tf.optimizers.SGD(learning_rate)
      # Update W and b following gradients.
      optimizer.apply_gradients(zip(gradients, [W, b]))  \
          # zip: 将可迭代的对象作为参数，将对象中对应的元素打包成一个个元组，然后返回由这些元组组成的列表
  ```

- 逻辑回归
