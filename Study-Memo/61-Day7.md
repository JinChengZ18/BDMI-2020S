# 61-Day7
## 1 Numpy

- 数据类型：与C语言基本对应。
- 广播 (broadcast) ：形状不相同的数组间的运算。
- 改变形状：reshape(arr, newshape, order=‘C’)/ ravel()（展平）/ transpose() 转置 / squeeze() 压缩空维度 / concatenate() 级联 / stack() 沿新轴堆叠 / hstack水平堆叠/ vstack垂直堆叠



## 2 深度学习与神经网络

- 常用激活函数（非线性变换）：Sigmoid (logistic), tanh, ReLU
- 人工神经元的具体建模：输入的线性加权叠加，非线性函数（激活函数）作用，激活函数模拟神经元激发的特性。
- 人工神经元模拟bool电路：通过改变权值能让人工神经元模拟与门、或门、非门、异或门、与非门等等
- 人工神经网络结构：前馈网络、反馈网络、记忆网络
- 卷积网络：（CNN） 输入是多维数组张量，卷积核也是多维数组张量。局部区域的权重W共用，卷积层，下采样层（Pooling），随机丢弃层（Dropout）组合使用
- 循环网络：（RNN）在时间上共享权重矩阵，随着时间的变化权重矩阵不改变。
- 人工神经网络的应用场景：图像分类
- 相关数学原理：映射：两个集合之间的对应关系；函数：一种特殊映射；函数逼近；泛函分析
- 万能近似定理：前馈网络能近似任意函数。
- 循环网络的近似能力：RNN是图灵完全等价的。



## 3 深度学习介绍

- 深度学习的三个领军人物Geoffrey Hinton, Yoshua Bengio, Yann LeCun
- 交叉熵——分类问题损失的度量函数
- 梯度下降法：让loss function沿着下降最快的方向
- 随机梯度下降：每次随机取一个样本进行梯度下降 实际训练：batch training，每次送几个训练样本进去训练，损失更新时应该用微积分求导法则。